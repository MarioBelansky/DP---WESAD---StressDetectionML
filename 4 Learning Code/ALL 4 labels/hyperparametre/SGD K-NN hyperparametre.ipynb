{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMqpU3+nmmj3lUjg5Dwt6ii"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","\n","from sklearn.model_selection import cross_val_score, train_test_split"],"metadata":{"id":"NRQ0pCG2Hqee","executionInfo":{"status":"ok","timestamp":1713308572033,"user_tz":-120,"elapsed":2,"user":{"displayName":"Mário Belánsky","userId":"10055823690112834981"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["dataO = pd.read_csv('WESAD_Oversample.csv')\n","\n","X = dataO.drop(columns=['labels'])\n","y = dataO['labels']\n","\n","import pandas as pd\n","import numpy as np\n","\n","def normalize_data(X):\n","    return (X - np.mean(X)) / np.std(X)\n","\n","def denormalize_data(normalized_data, original_data):\n","    return normalized_data * np.std(original_data) + np.mean(original_data)\n","\n","X = normalize_data(X)\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"Jnu2UJR7JhYo","executionInfo":{"status":"ok","timestamp":1713308578088,"user_tz":-120,"elapsed":898,"user":{"displayName":"Mário Belánsky","userId":"10055823690112834981"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","from scipy.stats import randint\n","\n","param_dist = {\n","    'n_neighbors': randint(1, 30),\n","    'weights': ['uniform', 'distance'],\n","    'p': [1, 2]\n","}\n","\n","knn_clf = KNeighborsClassifier()\n","\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","random_search = RandomizedSearchCV(knn_clf, param_distributions=param_dist, n_iter=100, cv=cv, verbose=1, random_state=42, n_jobs=-1)\n","\n","random_search.fit(X_train, y_train)\n","\n","print(\"Best Parameters:\", random_search.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fAinRFneJirW","executionInfo":{"status":"ok","timestamp":1713310262364,"user_tz":-120,"elapsed":1661540,"user":{"displayName":"Mário Belánsky","userId":"10055823690112834981"}},"outputId":"a2805340-c897-40b3-ceab-70939ee41d5e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 100 candidates, totalling 500 fits\n","Best Parameters: {'n_neighbors': 2, 'p': 1, 'weights': 'distance'}\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.metrics import accuracy_score\n","from scipy.stats import loguniform\n","\n","param_dist = {\n","    'alpha': loguniform(1e-4, 1e-1),\n","    'loss': ['hinge', 'log', 'modified_huber'],\n","    'penalty': ['l1', 'l2', 'elasticnet'],\n","    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n","    'eta0': loguniform(1e-5, 1e-1)\n","}\n","\n","sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n","\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","random_search = RandomizedSearchCV(sgd_clf, param_distributions=param_dist, n_iter=100, cv=cv, verbose=1, random_state=42, n_jobs=-1)\n","\n","random_search.fit(X_train, y_train)\n","\n","print(\"Best Parameters:\", random_search.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZLTaa-8JoZe","executionInfo":{"status":"ok","timestamp":1713311743922,"user_tz":-120,"elapsed":1481563,"user":{"displayName":"Mário Belánsky","userId":"10055823690112834981"}},"outputId":"b078875e-c1ee-48d0-8d59-197a7cf5b32e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Best Parameters: {'alpha': 0.021154290797261225, 'eta0': 0.057279044707996205, 'learning_rate': 'optimal', 'loss': 'log', 'penalty': 'elasticnet'}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_VZ6lc0yJ-RX"},"execution_count":null,"outputs":[]}]}